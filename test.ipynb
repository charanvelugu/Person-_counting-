{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hii\n"
     ]
    }
   ],
   "source": [
    "print(\"hii\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ultralytics in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (8.3.17)\n",
      "Requirement already satisfied: cvzone in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: numpy>=1.23.0 in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from ultralytics) (2.1.2)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from ultralytics) (3.9.2)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from ultralytics) (4.10.0.84)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from ultralytics) (11.0.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from ultralytics) (1.14.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from ultralytics) (2.5.0)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from ultralytics) (0.20.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from ultralytics) (4.66.5)\n",
      "Requirement already satisfied: psutil in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from ultralytics) (6.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from ultralytics) (2.2.3)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from ultralytics) (2.0.9)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.54.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2024.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2024.8.30)\n",
      "Requirement already satisfied: filelock in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.16.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.4.1)\n",
      "Requirement already satisfied: jinja2 in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2024.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\rupesh\\onedrive\\documents\\charan_project\\venv\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install  ultralytics cvzone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c:\\Users\\HP\\Downloads\\WhatsApp Video 2024-10-23 at 7.21.40 PM.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 264.1ms\n",
      "Speed: 3.7ms preprocess, 264.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[188, 574]\n",
      "[188, 574]\n",
      "[311, 546]\n",
      "[358, 511]\n",
      "[384, 491]\n",
      "[407, 474]\n",
      "[438, 449]\n",
      "[462, 432]\n",
      "[487, 410]\n",
      "[505, 393]\n",
      "[526, 374]\n",
      "[542, 355]\n",
      "[555, 339]\n",
      "[567, 323]\n",
      "[576, 311]\n",
      "[583, 296]\n",
      "[587, 286]\n",
      "[591, 274]\n",
      "[593, 264]\n",
      "[595, 251]\n",
      "[595, 241]\n",
      "[593, 231]\n",
      "[590, 221]\n",
      "[587, 212]\n",
      "[581, 204]\n",
      "[575, 198]\n",
      "[567, 191]\n",
      "[556, 183]\n",
      "[543, 172]\n",
      "[524, 162]\n",
      "[505, 154]\n",
      "[487, 146]\n",
      "[467, 139]\n",
      "[451, 135]\n",
      "[432, 128]\n",
      "[421, 125]\n",
      "[406, 123]\n",
      "[396, 119]\n",
      "[387, 117]\n",
      "[379, 115]\n",
      "[374, 113]\n",
      "[368, 111]\n",
      "[367, 110]\n",
      "[364, 109]\n",
      "[363, 109]\n",
      "[362, 109]\n",
      "[361, 109]\n",
      "[360, 109]\n",
      "[359, 109]\n",
      "[345, 115]\n",
      "[326, 127]\n",
      "[315, 135]\n",
      "[301, 145]\n",
      "[288, 154]\n",
      "[275, 162]\n",
      "[264, 170]\n",
      "[248, 182]\n",
      "[237, 190]\n",
      "[223, 200]\n",
      "[211, 209]\n",
      "[202, 213]\n",
      "[192, 219]\n",
      "[187, 222]\n",
      "[178, 227]\n",
      "[170, 231]\n",
      "[163, 236]\n",
      "[157, 239]\n",
      "[149, 245]\n",
      "[143, 248]\n",
      "[139, 253]\n",
      "[134, 256]\n",
      "[127, 260]\n",
      "[123, 263]\n",
      "[119, 266]\n",
      "[114, 269]\n",
      "[109, 271]\n",
      "[106, 273]\n",
      "[101, 276]\n",
      "[99, 277]\n",
      "[95, 279]\n",
      "[91, 283]\n",
      "[87, 286]\n",
      "[85, 287]\n",
      "[83, 291]\n",
      "[81, 292]\n",
      "[79, 294]\n",
      "[76, 295]\n",
      "[75, 295]\n",
      "[73, 297]\n",
      "[71, 297]\n",
      "[69, 297]\n",
      "[67, 297]\n",
      "[67, 297]\n",
      "[65, 297]\n",
      "[63, 297]\n",
      "[62, 299]\n",
      "[60, 299]\n",
      "[59, 300]\n",
      "[56, 302]\n",
      "[55, 304]\n",
      "[54, 306]\n",
      "[51, 307]\n",
      "[49, 311]\n",
      "[48, 312]\n",
      "[47, 314]\n",
      "[45, 317]\n",
      "[43, 319]\n",
      "[42, 320]\n",
      "[39, 323]\n",
      "[37, 324]\n",
      "[35, 326]\n",
      "[33, 327]\n",
      "[31, 329]\n",
      "[29, 331]\n",
      "[27, 331]\n",
      "[26, 332]\n",
      "[26, 333]\n",
      "[25, 333]\n",
      "[24, 334]\n",
      "[24, 335]\n",
      "[23, 335]\n",
      "[23, 335]\n",
      "[15, 335]\n",
      "[4, 335]\n",
      "[15, 381]\n",
      "[49, 398]\n",
      "[73, 407]\n",
      "[111, 422]\n",
      "[139, 427]\n",
      "[180, 431]\n",
      "[207, 431]\n",
      "[251, 429]\n",
      "[282, 427]\n",
      "[324, 417]\n",
      "[352, 410]\n",
      "[394, 395]\n",
      "[419, 386]\n",
      "[463, 367]\n",
      "[483, 356]\n",
      "[523, 340]\n",
      "[543, 332]\n",
      "[579, 320]\n",
      "[598, 314]\n",
      "[626, 309]\n",
      "[642, 307]\n",
      "[660, 305]\n",
      "[675, 305]\n",
      "[687, 305]\n",
      "[697, 306]\n",
      "[707, 307]\n",
      "[715, 309]\n",
      "[723, 311]\n",
      "[731, 313]\n",
      "[737, 315]\n",
      "[742, 316]\n",
      "[747, 318]\n",
      "[752, 319]\n",
      "[755, 320]\n",
      "[756, 321]\n",
      "[758, 321]\n",
      "[759, 322]\n",
      "[759, 322]\n",
      "[759, 323]\n",
      "[759, 322]\n",
      "[756, 320]\n",
      "[754, 318]\n",
      "[749, 316]\n",
      "[746, 315]\n",
      "[741, 312]\n",
      "[737, 311]\n",
      "[732, 309]\n",
      "[728, 308]\n",
      "[723, 307]\n",
      "[717, 307]\n",
      "[710, 306]\n",
      "[702, 306]\n",
      "[695, 306]\n",
      "[687, 307]\n",
      "[679, 308]\n",
      "[670, 311]\n",
      "[658, 316]\n",
      "[647, 319]\n",
      "[637, 323]\n",
      "[627, 327]\n",
      "[619, 330]\n",
      "[610, 333]\n",
      "[602, 336]\n",
      "[597, 339]\n",
      "[591, 342]\n",
      "[586, 343]\n",
      "[584, 345]\n",
      "[582, 347]\n",
      "[580, 347]\n",
      "[579, 348]\n",
      "[579, 348]\n",
      "[579, 349]\n",
      "[578, 349]\n",
      "[577, 349]\n",
      "[577, 350]\n",
      "\n",
      "0: 384x640 (no detections), 232.6ms\n",
      "Speed: 0.0ms preprocess, 232.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 246.9ms\n",
      "Speed: 0.0ms preprocess, 246.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 203.8ms\n",
      "Speed: 12.5ms preprocess, 203.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 249.7ms\n",
      "Speed: 0.0ms preprocess, 249.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 262.6ms\n",
      "Speed: 0.0ms preprocess, 262.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 231.8ms\n",
      "Speed: 11.0ms preprocess, 231.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 216.3ms\n",
      "Speed: 2.5ms preprocess, 216.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 237.0ms\n",
      "Speed: 2.3ms preprocess, 237.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 251.3ms\n",
      "Speed: 0.0ms preprocess, 251.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 203.8ms\n",
      "Speed: 0.0ms preprocess, 203.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 217.6ms\n",
      "Speed: 0.0ms preprocess, 217.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 218.7ms\n",
      "Speed: 0.0ms preprocess, 218.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 216.5ms\n",
      "Speed: 0.0ms preprocess, 216.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 207.0ms\n",
      "Speed: 12.4ms preprocess, 207.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 246.4ms\n",
      "Speed: 0.0ms preprocess, 246.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 236.8ms\n",
      "Speed: 0.0ms preprocess, 236.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 214.9ms\n",
      "Speed: 0.0ms preprocess, 214.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 199.3ms\n",
      "Speed: 1.0ms preprocess, 199.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 199.7ms\n",
      "Speed: 0.0ms preprocess, 199.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 201.5ms\n",
      "Speed: 0.0ms preprocess, 201.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 263.7ms\n",
      "Speed: 0.0ms preprocess, 263.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 278.4ms\n",
      "Speed: 0.0ms preprocess, 278.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 260.3ms\n",
      "Speed: 10.6ms preprocess, 260.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 265.8ms\n",
      "Speed: 0.0ms preprocess, 265.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 254.9ms\n",
      "Speed: 0.0ms preprocess, 254.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 244.1ms\n",
      "Speed: 6.0ms preprocess, 244.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 232.8ms\n",
      "Speed: 0.0ms preprocess, 232.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 266.4ms\n",
      "Speed: 0.0ms preprocess, 266.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 229.3ms\n",
      "Speed: 3.5ms preprocess, 229.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 193.3ms\n",
      "Speed: 0.0ms preprocess, 193.3ms inference, 12.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 216.7ms\n",
      "Speed: 0.0ms preprocess, 216.7ms inference, 13.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 217.1ms\n",
      "Speed: 0.0ms preprocess, 217.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 217.0ms\n",
      "Speed: 0.0ms preprocess, 217.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 198.1ms\n",
      "Speed: 0.0ms preprocess, 198.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 233.7ms\n",
      "Speed: 12.0ms preprocess, 233.7ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 216.2ms\n",
      "Speed: 0.0ms preprocess, 216.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 199.2ms\n",
      "Speed: 0.0ms preprocess, 199.2ms inference, 0.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 217.3ms\n",
      "Speed: 0.0ms preprocess, 217.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 163.9ms\n",
      "Speed: 3.3ms preprocess, 163.9ms inference, 13.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 246.0ms\n",
      "Speed: 0.0ms preprocess, 246.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 234.2ms\n",
      "Speed: 0.0ms preprocess, 234.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 219.8ms\n",
      "Speed: 0.0ms preprocess, 219.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 200.1ms\n",
      "Speed: 16.9ms preprocess, 200.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 218.1ms\n",
      "Speed: 0.0ms preprocess, 218.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 198.3ms\n",
      "Speed: 0.0ms preprocess, 198.3ms inference, 5.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 204.5ms\n",
      "Speed: 2.1ms preprocess, 204.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 250.2ms\n",
      "Speed: 0.0ms preprocess, 250.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 227.6ms\n",
      "Speed: 0.0ms preprocess, 227.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 225.7ms\n",
      "Speed: 0.0ms preprocess, 225.7ms inference, 6.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 209.9ms\n",
      "Speed: 6.6ms preprocess, 209.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 237.4ms\n",
      "Speed: 12.0ms preprocess, 237.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 245.0ms\n",
      "Speed: 0.0ms preprocess, 245.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 235.2ms\n",
      "Speed: 15.3ms preprocess, 235.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 220.9ms\n",
      "Speed: 0.4ms preprocess, 220.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 227.6ms\n",
      "Speed: 0.0ms preprocess, 227.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 219.9ms\n",
      "Speed: 13.1ms preprocess, 219.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 245.0ms\n",
      "Speed: 3.2ms preprocess, 245.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 248.5ms\n",
      "Speed: 2.5ms preprocess, 248.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 229.5ms\n",
      "Speed: 0.0ms preprocess, 229.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 266.7ms\n",
      "Speed: 0.0ms preprocess, 266.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 231.0ms\n",
      "Speed: 0.0ms preprocess, 231.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 231.6ms\n",
      "Speed: 0.0ms preprocess, 231.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 261.1ms\n",
      "Speed: 0.0ms preprocess, 261.1ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 244.6ms\n",
      "Speed: 0.0ms preprocess, 244.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 247.3ms\n",
      "Speed: 2.5ms preprocess, 247.3ms inference, 4.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 228.2ms\n",
      "Speed: 3.3ms preprocess, 228.2ms inference, 11.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 232.8ms\n",
      "Speed: 0.0ms preprocess, 232.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 250.7ms\n",
      "Speed: 0.0ms preprocess, 250.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 215.8ms\n",
      "Speed: 6.0ms preprocess, 215.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 198.2ms\n",
      "Speed: 11.8ms preprocess, 198.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 250.8ms\n",
      "Speed: 6.1ms preprocess, 250.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 252.8ms\n",
      "Speed: 0.0ms preprocess, 252.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 215.6ms\n",
      "Speed: 1.7ms preprocess, 215.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 201.7ms\n",
      "Speed: 4.6ms preprocess, 201.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 211.8ms\n",
      "Speed: 0.0ms preprocess, 211.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 210.5ms\n",
      "Speed: 13.1ms preprocess, 210.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 232.2ms\n",
      "Speed: 1.0ms preprocess, 232.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 253.0ms\n",
      "Speed: 10.5ms preprocess, 253.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 233.7ms\n",
      "Speed: 0.0ms preprocess, 233.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 205.6ms\n",
      "Speed: 8.3ms preprocess, 205.6ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 266.0ms\n",
      "Speed: 1.8ms preprocess, 266.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 244.6ms\n",
      "Speed: 0.0ms preprocess, 244.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 246.2ms\n",
      "Speed: 0.0ms preprocess, 246.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 215.4ms\n",
      "Speed: 0.0ms preprocess, 215.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 199.4ms\n",
      "Speed: 1.4ms preprocess, 199.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 249.3ms\n",
      "Speed: 0.0ms preprocess, 249.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 249.6ms\n",
      "Speed: 0.0ms preprocess, 249.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 211.8ms\n",
      "Speed: 2.4ms preprocess, 211.8ms inference, 11.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 289.3ms\n",
      "Speed: 0.0ms preprocess, 289.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 216.5ms\n",
      "Speed: 1.5ms preprocess, 216.5ms inference, 13.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 190.3ms\n",
      "Speed: 9.1ms preprocess, 190.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 183.9ms\n",
      "Speed: 8.1ms preprocess, 183.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 216.9ms\n",
      "Speed: 0.0ms preprocess, 216.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 216.5ms\n",
      "Speed: 0.0ms preprocess, 216.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import cvzone\n",
    "import numpy as np\n",
    "\n",
    "def RGB(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_MOUSEMOVE:\n",
    "        point = [x, y]\n",
    "        print(point)\n",
    "\n",
    "cv2.namedWindow('RGB')\n",
    "cv2.setMouseCallback('RGB', RGB)\n",
    "\n",
    "# Load the YOLO11 model\n",
    "model = YOLO(\"yolo11s.pt\")\n",
    "names=model.model.names\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(\"C:\\Rupesh\\OneDrive\\Documents\\charan_project\\yolo11_suspicious_activity-main\\WhatsApp Video 2024-10-23 at 7.21.40 PM.mp4\")\n",
    "count=0\n",
    "cy1=261\n",
    "cy2=286\n",
    "offset=8\n",
    "inp={}\n",
    "enter=[]\n",
    "exp={}\n",
    "exitp=[]\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    count += 1\n",
    "    if count % 3 != 0:\n",
    "        continue\n",
    "\n",
    "    frame = cv2.resize(frame, (1020, 600))\n",
    "    \n",
    "    # Run YOLO11 tracking on the frame, persisting tracks between frames\n",
    "    results = model.track(frame, persist=True,classes=0)\n",
    "\n",
    "    # Check if there are any boxes in the results\n",
    "    if results[0].boxes is not None and results[0].boxes.id is not None:\n",
    "        # Get the boxes (x, y, w, h), class IDs, track IDs, and confidences\n",
    "        boxes = results[0].boxes.xyxy.int().cpu().tolist()  # Bounding boxes\n",
    "        class_ids = results[0].boxes.cls.int().cpu().tolist()  # Class IDs\n",
    "        track_ids = results[0].boxes.id.int().cpu().tolist()  # Track IDs\n",
    "        confidences = results[0].boxes.conf.cpu().tolist()  # Confidence score\n",
    "       \n",
    "        for box, class_id, track_id, conf in zip(boxes, class_ids, track_ids, confidences):\n",
    "            c = names[class_id]\n",
    "            x1, y1, x2, y2 = box\n",
    "            cv2.rectangle(frame,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "            cvzone.putTextRect(frame,f'{track_id}',(x1,y2),1,1)\n",
    "            cvzone.putTextRect(frame,f'{c}',(x1,y1),1,1)\n",
    "                  \n",
    "\n",
    "    cv2.line(frame,(6,286),(1018,286),(0,0,255),2)\n",
    "    cv2.line(frame,(6,261),(1018,261),(255,0,255),2)\n",
    "\n",
    "    cv2.imshow(\"RGB\", frame)\n",
    "    if cv2.waitKey(0) & 0xFF == ord(\"q\"):\n",
    "       break\n",
    "\n",
    "# Release the video capture object and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 (no detections), 295.9ms\n",
      "Speed: 0.0ms preprocess, 295.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[511, 552]\n",
      "[604, 516]\n",
      "[616, 507]\n",
      "[631, 497]\n",
      "[644, 485]\n",
      "\n",
      "0: 384x640 (no detections), 293.3ms\n",
      "Speed: 1.7ms preprocess, 293.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[565, 198]\n",
      "[562, 199]\n",
      "[560, 200]\n",
      "\n",
      "0: 384x640 1 person, 244.4ms\n",
      "Speed: 0.0ms preprocess, 244.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[540, 204]\n",
      "\n",
      "0: 384x640 1 person, 280.0ms\n",
      "Speed: 0.0ms preprocess, 280.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 278.6ms\n",
      "Speed: 0.0ms preprocess, 278.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 278.7ms\n",
      "Speed: 0.0ms preprocess, 278.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 256.0ms\n",
      "Speed: 0.0ms preprocess, 256.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 260.3ms\n",
      "Speed: 0.0ms preprocess, 260.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 216.3ms\n",
      "Speed: 0.0ms preprocess, 216.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 216.5ms\n",
      "Speed: 3.3ms preprocess, 216.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 216.8ms\n",
      "Speed: 0.0ms preprocess, 216.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 216.1ms\n",
      "Speed: 0.0ms preprocess, 216.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 219.0ms\n",
      "Speed: 0.0ms preprocess, 219.0ms inference, 8.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 236.8ms\n",
      "Speed: 8.5ms preprocess, 236.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 259.4ms\n",
      "Speed: 0.0ms preprocess, 259.4ms inference, 12.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 264.3ms\n",
      "Speed: 0.0ms preprocess, 264.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[540, 204]\n",
      "\n",
      "0: 384x640 1 person, 292.8ms\n",
      "Speed: 4.5ms preprocess, 292.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 260.0ms\n",
      "Speed: 2.7ms preprocess, 260.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 255.6ms\n",
      "Speed: 0.0ms preprocess, 255.6ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 226.7ms\n",
      "Speed: 0.0ms preprocess, 226.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 261.5ms\n",
      "Speed: 0.0ms preprocess, 261.5ms inference, 14.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 227.7ms\n",
      "Speed: 0.0ms preprocess, 227.7ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 264.4ms\n",
      "Speed: 0.0ms preprocess, 264.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 311.0ms\n",
      "Speed: 0.0ms preprocess, 311.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 249.9ms\n",
      "Speed: 0.9ms preprocess, 249.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 211.2ms\n",
      "Speed: 5.7ms preprocess, 211.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 242.4ms\n",
      "Speed: 0.0ms preprocess, 242.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 262.0ms\n",
      "Speed: 0.0ms preprocess, 262.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 250.5ms\n",
      "Speed: 8.5ms preprocess, 250.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 282.6ms\n",
      "Speed: 0.0ms preprocess, 282.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 279.0ms\n",
      "Speed: 0.0ms preprocess, 279.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 259.2ms\n",
      "Speed: 6.5ms preprocess, 259.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 241.0ms\n",
      "Speed: 0.0ms preprocess, 241.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 299.5ms\n",
      "Speed: 0.0ms preprocess, 299.5ms inference, 9.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 367.2ms\n",
      "Speed: 0.0ms preprocess, 367.2ms inference, 16.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 350.5ms\n",
      "Speed: 0.0ms preprocess, 350.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 326.1ms\n",
      "Speed: 8.0ms preprocess, 326.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 342.5ms\n",
      "Speed: 8.0ms preprocess, 342.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 342.2ms\n",
      "Speed: 7.5ms preprocess, 342.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 342.6ms\n",
      "Speed: 7.6ms preprocess, 342.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 328.1ms\n",
      "Speed: 0.0ms preprocess, 328.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 325.8ms\n",
      "Speed: 7.6ms preprocess, 325.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 174.9ms\n",
      "Speed: 5.9ms preprocess, 174.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 196.2ms\n",
      "Speed: 3.7ms preprocess, 196.2ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 282.3ms\n",
      "Speed: 0.0ms preprocess, 282.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 258.6ms\n",
      "Speed: 7.5ms preprocess, 258.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 283.3ms\n",
      "Speed: 0.0ms preprocess, 283.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 254.4ms\n",
      "Speed: 0.0ms preprocess, 254.4ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[468, 197]\n",
      "[472, 202]\n",
      "[477, 207]\n",
      "\n",
      "0: 384x640 1 person, 342.1ms\n",
      "Speed: 8.5ms preprocess, 342.1ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[604, 265]\n",
      "\n",
      "0: 384x640 1 person, 334.2ms\n",
      "Speed: 0.0ms preprocess, 334.2ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 299.3ms\n",
      "Speed: 0.0ms preprocess, 299.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 278.8ms\n",
      "Speed: 7.6ms preprocess, 278.8ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 309.0ms\n",
      "Speed: 8.1ms preprocess, 309.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 285.8ms\n",
      "Speed: 0.0ms preprocess, 285.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 184.6ms\n",
      "Speed: 2.4ms preprocess, 184.6ms inference, 12.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 211.6ms\n",
      "Speed: 0.0ms preprocess, 211.6ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 349.0ms\n",
      "Speed: 0.0ms preprocess, 349.0ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[604, 265]\n",
      "\n",
      "0: 384x640 (no detections), 275.9ms\n",
      "Speed: 8.0ms preprocess, 275.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 295.8ms\n",
      "Speed: 4.3ms preprocess, 295.8ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 303.8ms\n",
      "Speed: 5.6ms preprocess, 303.8ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 224.2ms\n",
      "Speed: 4.9ms preprocess, 224.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[604, 265]\n",
      "\n",
      "0: 384x640 (no detections), 242.9ms\n",
      "Speed: 4.0ms preprocess, 242.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 290.7ms\n",
      "Speed: 3.4ms preprocess, 290.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 310.7ms\n",
      "Speed: 4.0ms preprocess, 310.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 283.5ms\n",
      "Speed: 5.0ms preprocess, 283.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 346.4ms\n",
      "Speed: 6.0ms preprocess, 346.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 371.1ms\n",
      "Speed: 4.4ms preprocess, 371.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 367.5ms\n",
      "Speed: 5.0ms preprocess, 367.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 257.1ms\n",
      "Speed: 5.0ms preprocess, 257.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 335.6ms\n",
      "Speed: 3.0ms preprocess, 335.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 382.4ms\n",
      "Speed: 5.0ms preprocess, 382.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 378.7ms\n",
      "Speed: 5.0ms preprocess, 378.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 330.4ms\n",
      "Speed: 6.0ms preprocess, 330.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 327.9ms\n",
      "Speed: 3.9ms preprocess, 327.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 375.6ms\n",
      "Speed: 6.0ms preprocess, 375.6ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 357.0ms\n",
      "Speed: 5.0ms preprocess, 357.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 343.1ms\n",
      "Speed: 5.2ms preprocess, 343.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 360.0ms\n",
      "Speed: 5.0ms preprocess, 360.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 376.3ms\n",
      "Speed: 5.9ms preprocess, 376.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 368.2ms\n",
      "Speed: 2.9ms preprocess, 368.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 341.9ms\n",
      "Speed: 3.0ms preprocess, 341.9ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 352.0ms\n",
      "Speed: 4.0ms preprocess, 352.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 324.9ms\n",
      "Speed: 5.0ms preprocess, 324.9ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 351.9ms\n",
      "Speed: 5.8ms preprocess, 351.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 375.3ms\n",
      "Speed: 4.9ms preprocess, 375.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 377.4ms\n",
      "Speed: 5.1ms preprocess, 377.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 367.1ms\n",
      "Speed: 5.9ms preprocess, 367.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 324.9ms\n",
      "Speed: 5.3ms preprocess, 324.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 344.7ms\n",
      "Speed: 4.0ms preprocess, 344.7ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 378.2ms\n",
      "Speed: 6.0ms preprocess, 378.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 288.6ms\n",
      "Speed: 5.0ms preprocess, 288.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 332.8ms\n",
      "Speed: 3.0ms preprocess, 332.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 362.4ms\n",
      "Speed: 4.0ms preprocess, 362.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 372.9ms\n",
      "Speed: 3.9ms preprocess, 372.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 320.9ms\n",
      "Speed: 5.0ms preprocess, 320.9ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 385.0ms\n",
      "Speed: 4.9ms preprocess, 385.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 393.7ms\n",
      "Speed: 5.9ms preprocess, 393.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 359.6ms\n",
      "Speed: 5.0ms preprocess, 359.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 313.0ms\n",
      "Speed: 5.0ms preprocess, 313.0ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 355.1ms\n",
      "Speed: 5.0ms preprocess, 355.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 359.4ms\n",
      "Speed: 3.9ms preprocess, 359.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 361.6ms\n",
      "Speed: 5.2ms preprocess, 361.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 339.9ms\n",
      "Speed: 4.0ms preprocess, 339.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 360.6ms\n",
      "Speed: 3.9ms preprocess, 360.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 330.2ms\n",
      "Speed: 4.8ms preprocess, 330.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 374.5ms\n",
      "Speed: 6.1ms preprocess, 374.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 333.1ms\n",
      "Speed: 5.0ms preprocess, 333.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 370.7ms\n",
      "Speed: 3.1ms preprocess, 370.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 335.2ms\n",
      "Speed: 5.2ms preprocess, 335.2ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 340.7ms\n",
      "Speed: 3.0ms preprocess, 340.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 379.1ms\n",
      "Speed: 4.1ms preprocess, 379.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 378.0ms\n",
      "Speed: 5.0ms preprocess, 378.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 374.1ms\n",
      "Speed: 6.0ms preprocess, 374.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 386.6ms\n",
      "Speed: 5.0ms preprocess, 386.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 366.4ms\n",
      "Speed: 5.0ms preprocess, 366.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 369.8ms\n",
      "Speed: 5.0ms preprocess, 369.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 340.1ms\n",
      "Speed: 4.0ms preprocess, 340.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 363.2ms\n",
      "Speed: 5.9ms preprocess, 363.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 355.0ms\n",
      "Speed: 5.0ms preprocess, 355.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 370.1ms\n",
      "Speed: 4.1ms preprocess, 370.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 389.0ms\n",
      "Speed: 4.9ms preprocess, 389.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 366.9ms\n",
      "Speed: 6.0ms preprocess, 366.9ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 389.7ms\n",
      "Speed: 2.0ms preprocess, 389.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 329.5ms\n",
      "Speed: 3.0ms preprocess, 329.5ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 351.0ms\n",
      "Speed: 2.0ms preprocess, 351.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 377.0ms\n",
      "Speed: 4.0ms preprocess, 377.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 360.6ms\n",
      "Speed: 5.0ms preprocess, 360.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 382.0ms\n",
      "Speed: 4.9ms preprocess, 382.0ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 336.7ms\n",
      "Speed: 5.2ms preprocess, 336.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 377.6ms\n",
      "Speed: 6.0ms preprocess, 377.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 360.4ms\n",
      "Speed: 5.9ms preprocess, 360.4ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 330.0ms\n",
      "Speed: 5.5ms preprocess, 330.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 360.1ms\n",
      "Speed: 6.0ms preprocess, 360.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 316.5ms\n",
      "Speed: 2.0ms preprocess, 316.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 304.3ms\n",
      "Speed: 2.6ms preprocess, 304.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 283.8ms\n",
      "Speed: 5.0ms preprocess, 283.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 373.0ms\n",
      "Speed: 4.0ms preprocess, 373.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 323.5ms\n",
      "Speed: 3.3ms preprocess, 323.5ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 336.9ms\n",
      "Speed: 3.2ms preprocess, 336.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 305.3ms\n",
      "Speed: 5.0ms preprocess, 305.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 371.5ms\n",
      "Speed: 4.0ms preprocess, 371.5ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 363.6ms\n",
      "Speed: 6.0ms preprocess, 363.6ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 319.4ms\n",
      "Speed: 4.0ms preprocess, 319.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 310.7ms\n",
      "Speed: 7.0ms preprocess, 310.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 344.5ms\n",
      "Speed: 5.2ms preprocess, 344.5ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 317.5ms\n",
      "Speed: 4.5ms preprocess, 317.5ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 347.2ms\n",
      "Speed: 2.9ms preprocess, 347.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 354.5ms\n",
      "Speed: 2.9ms preprocess, 354.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 364.1ms\n",
      "Speed: 4.0ms preprocess, 364.1ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 362.7ms\n",
      "Speed: 5.0ms preprocess, 362.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 252.5ms\n",
      "Speed: 2.5ms preprocess, 252.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 328.0ms\n",
      "Speed: 1.0ms preprocess, 328.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 307.3ms\n",
      "Speed: 7.0ms preprocess, 307.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 307.8ms\n",
      "Speed: 4.9ms preprocess, 307.8ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 344.0ms\n",
      "Speed: 4.0ms preprocess, 344.0ms inference, 5.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 326.3ms\n",
      "Speed: 3.9ms preprocess, 326.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 368.0ms\n",
      "Speed: 3.0ms preprocess, 368.0ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 376.1ms\n",
      "Speed: 3.9ms preprocess, 376.1ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 344.7ms\n",
      "Speed: 3.0ms preprocess, 344.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 308.8ms\n",
      "Speed: 4.1ms preprocess, 308.8ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 372.3ms\n",
      "Speed: 4.1ms preprocess, 372.3ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 383.1ms\n",
      "Speed: 6.2ms preprocess, 383.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 378.2ms\n",
      "Speed: 5.1ms preprocess, 378.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 386.2ms\n",
      "Speed: 4.0ms preprocess, 386.2ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 380.3ms\n",
      "Speed: 5.0ms preprocess, 380.3ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 413.8ms\n",
      "Speed: 7.0ms preprocess, 413.8ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 362.6ms\n",
      "Speed: 5.9ms preprocess, 362.6ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 368.2ms\n",
      "Speed: 4.9ms preprocess, 368.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 410.6ms\n",
      "Speed: 5.0ms preprocess, 410.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 318.9ms\n",
      "Speed: 4.1ms preprocess, 318.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 367.3ms\n",
      "Speed: 5.4ms preprocess, 367.3ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 370.7ms\n",
      "Speed: 4.0ms preprocess, 370.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 344.6ms\n",
      "Speed: 4.9ms preprocess, 344.6ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 323.0ms\n",
      "Speed: 5.0ms preprocess, 323.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 385.0ms\n",
      "Speed: 4.8ms preprocess, 385.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 387.7ms\n",
      "Speed: 5.0ms preprocess, 387.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 387.6ms\n",
      "Speed: 4.0ms preprocess, 387.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 398.0ms\n",
      "Speed: 5.8ms preprocess, 398.0ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 386.7ms\n",
      "Speed: 4.0ms preprocess, 386.7ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 401.1ms\n",
      "Speed: 5.0ms preprocess, 401.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 392.7ms\n",
      "Speed: 3.0ms preprocess, 392.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 372.6ms\n",
      "Speed: 4.0ms preprocess, 372.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 372.0ms\n",
      "Speed: 4.9ms preprocess, 372.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 363.4ms\n",
      "Speed: 5.0ms preprocess, 363.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 392.0ms\n",
      "Speed: 5.0ms preprocess, 392.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 416.4ms\n",
      "Speed: 3.0ms preprocess, 416.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 407.0ms\n",
      "Speed: 3.0ms preprocess, 407.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 391.7ms\n",
      "Speed: 5.0ms preprocess, 391.7ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 388.9ms\n",
      "Speed: 3.0ms preprocess, 388.9ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 414.1ms\n",
      "Speed: 4.0ms preprocess, 414.1ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 325.5ms\n",
      "Speed: 3.0ms preprocess, 325.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 299.9ms\n",
      "Speed: 4.0ms preprocess, 299.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 322.1ms\n",
      "Speed: 5.0ms preprocess, 322.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 378.6ms\n",
      "Speed: 3.4ms preprocess, 378.6ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 399.0ms\n",
      "Speed: 5.5ms preprocess, 399.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 382.4ms\n",
      "Speed: 5.0ms preprocess, 382.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 380.1ms\n",
      "Speed: 5.0ms preprocess, 380.1ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 420.5ms\n",
      "Speed: 3.0ms preprocess, 420.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 397.3ms\n",
      "Speed: 5.4ms preprocess, 397.3ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 392.1ms\n",
      "Speed: 4.1ms preprocess, 392.1ms inference, 5.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 363.4ms\n",
      "Speed: 4.2ms preprocess, 363.4ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 411.8ms\n",
      "Speed: 2.9ms preprocess, 411.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 351.1ms\n",
      "Speed: 3.0ms preprocess, 351.1ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 328.1ms\n",
      "Speed: 5.0ms preprocess, 328.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 351.2ms\n",
      "Speed: 3.9ms preprocess, 351.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 326.9ms\n",
      "Speed: 5.0ms preprocess, 326.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 297.3ms\n",
      "Speed: 4.0ms preprocess, 297.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 355.6ms\n",
      "Speed: 5.0ms preprocess, 355.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 384.3ms\n",
      "Speed: 5.4ms preprocess, 384.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 400.0ms\n",
      "Speed: 5.0ms preprocess, 400.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 413.5ms\n",
      "Speed: 5.0ms preprocess, 413.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 377.0ms\n",
      "Speed: 5.7ms preprocess, 377.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 346.5ms\n",
      "Speed: 5.0ms preprocess, 346.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 377.0ms\n",
      "Speed: 4.0ms preprocess, 377.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 311.1ms\n",
      "Speed: 5.0ms preprocess, 311.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 377.8ms\n",
      "Speed: 4.1ms preprocess, 377.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 404.9ms\n",
      "Speed: 3.4ms preprocess, 404.9ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 341.3ms\n",
      "Speed: 3.0ms preprocess, 341.3ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import cvzone\n",
    "import numpy as np\n",
    "\n",
    "def RGB(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_MOUSEMOVE:\n",
    "        point = [x, y]\n",
    "        print(point)\n",
    "\n",
    "cv2.namedWindow('RGB')\n",
    "cv2.setMouseCallback('RGB', RGB)\n",
    "\n",
    "# Load the YOLO11 model\n",
    "model = YOLO(\"yolo11s.pt\")\n",
    "names=model.model.names\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(\"C:\\Rupesh\\OneDrive\\Documents\\charan_project\\yolo11_suspicious_activity-main\\WhatsApp Video 2024-10-23 at 7.21.40 PM.mp4\")\n",
    "count=0\n",
    "cy1=335\n",
    "cy2=380\n",
    "offset=10\n",
    "inp={}\n",
    "enter=[]\n",
    "exp={}\n",
    "exitp=[]\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    count += 1\n",
    "    if count % 3 != 0:\n",
    "        continue\n",
    "\n",
    "    frame = cv2.resize(frame, (1020, 600))\n",
    "    \n",
    "    # Run YOLO11 tracking on the frame, persisting tracks between frames\n",
    "    results = model.track(frame, persist=True,classes=0)\n",
    "\n",
    "    # Check if there are any boxes in the results\n",
    "    if results[0].boxes is not None and results[0].boxes.id is not None:\n",
    "        # Get the boxes (x, y, w, h), class IDs, track IDs, and confidences\n",
    "        boxes = results[0].boxes.xyxy.int().cpu().tolist()  # Bounding boxes\n",
    "        class_ids = results[0].boxes.cls.int().cpu().tolist()  # Class IDs\n",
    "        track_ids = results[0].boxes.id.int().cpu().tolist()  # Track IDs\n",
    "        confidences = results[0].boxes.conf.cpu().tolist()  # Confidence score\n",
    "       \n",
    "        for box, class_id, track_id, conf in zip(boxes, class_ids, track_ids, confidences):\n",
    "            c = names[class_id]\n",
    "            x1, y1, x2, y2 = box\n",
    "            cx = int(x1+x2)//2\n",
    "            cy = int(y1+y2)//2\n",
    "            if cy1 <(cy+offset) and cy1 > (cy-offset):\n",
    "                inp[track_id] = (cx,cy)\n",
    "            if track_id in inp:\n",
    "                if cy2 <(cy+offset) and cy2 > (cy-offset):\n",
    "\n",
    "                    cv2.circle(frame,(cx,cy),4,(255,0,0),-1)\n",
    "                    cv2.rectangle(frame,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "                    cvzone.putTextRect(frame,f'{track_id}',(x1,y2),1,1)\n",
    "                    cvzone.putTextRect(frame,f'{c}',(x1,y1),1,1)\n",
    "                    if enter.count(track_id)==0:\n",
    "                        enter.append(track_id)\n",
    "            if cy2 <(cy+offset) and cy2 > (cy-offset):\n",
    "                exp[track_id] = (cx,cy)\n",
    "            if track_id in exp:\n",
    "                if cy1 <(cy+offset) and cy1 > (cy-offset):\n",
    "\n",
    "                    cv2.circle(frame,(cx,cy),4,(255,0,0),-1)\n",
    "                    cv2.rectangle(frame,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "                    cvzone.putTextRect(frame,f'{track_id}',(x1,y2),1,1)\n",
    "                    cvzone.putTextRect(frame,f'{c}',(x1,y1),1,1)\n",
    "                    if exitp.count(track_id)==0:\n",
    "                        exitp.append(track_id)\n",
    "        \n",
    "            \n",
    "                  \n",
    "\n",
    "    cv2.line(frame,(6,335),(1018,335),(0,0,255),2)\n",
    "    cv2.line(frame,(6,380),(1018,380),(255,0,255),2)\n",
    "    enterp = len(enter)\n",
    "    exitp1 = len(exitp)\n",
    "    cvzone.putTextRect(frame,f'EnterPerson : - {enterp}',(50,60),2,2)\n",
    "    cvzone.putTextRect(frame,f'ExitPerson : - {exitp1}',(50,160),2,2)\n",
    "\n",
    "    cv2.imshow(\"RGB\", frame)\n",
    "    if cv2.waitKey(5) & 0xFF == ord(\"q\"):\n",
    "       break\n",
    "\n",
    "# Release the video capture object and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x384 1 person, 295.4ms\n",
      "Speed: 2.8ms preprocess, 295.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "[582, 359]\n",
      "\n",
      "0: 640x384 1 person, 226.2ms\n",
      "Speed: 0.0ms preprocess, 226.2ms inference, 8.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 239.9ms\n",
      "Speed: 15.3ms preprocess, 239.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 189.3ms\n",
      "Speed: 2.3ms preprocess, 189.3ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 166.9ms\n",
      "Speed: 0.0ms preprocess, 166.9ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 166.5ms\n",
      "Speed: 0.0ms preprocess, 166.5ms inference, 10.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 159.4ms\n",
      "Speed: 0.9ms preprocess, 159.4ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 184.0ms\n",
      "Speed: 8.1ms preprocess, 184.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 149.2ms\n",
      "Speed: 0.0ms preprocess, 149.2ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 166.1ms\n",
      "Speed: 0.0ms preprocess, 166.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 181.8ms\n",
      "Speed: 0.0ms preprocess, 181.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 166.0ms\n",
      "Speed: 0.0ms preprocess, 166.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 191.1ms\n",
      "Speed: 0.0ms preprocess, 191.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 220.2ms\n",
      "Speed: 2.2ms preprocess, 220.2ms inference, 3.7ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 224.7ms\n",
      "Speed: 0.0ms preprocess, 224.7ms inference, 6.9ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 216.6ms\n",
      "Speed: 0.0ms preprocess, 216.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 197.6ms\n",
      "Speed: 0.0ms preprocess, 197.6ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 226.8ms\n",
      "Speed: 0.0ms preprocess, 226.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 179.8ms\n",
      "Speed: 0.0ms preprocess, 179.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 183.6ms\n",
      "Speed: 8.3ms preprocess, 183.6ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 158.1ms\n",
      "Speed: 1.2ms preprocess, 158.1ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 218.0ms\n",
      "Speed: 0.0ms preprocess, 218.0ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n",
      "\n",
      "0: 640x384 2 persons, 167.8ms\n",
      "Speed: 0.0ms preprocess, 167.8ms inference, 0.0ms postprocess per image at shape (1, 3, 640, 384)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import cvzone\n",
    "\n",
    "def RGB(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_MOUSEMOVE:\n",
    "        point = [x, y]\n",
    "        print(point)\n",
    "\n",
    "cv2.namedWindow('RGB')\n",
    "cv2.setMouseCallback('RGB', RGB)\n",
    "\n",
    "# Load the YOLO11 model\n",
    "model = YOLO(\"yolo11s.pt\")\n",
    "names = model.model.names\n",
    "\n",
    "# Open the input video file\n",
    "cap = cv2.VideoCapture(r\"C:\\Rupesh\\OneDrive\\Documents\\charan_project\\yolo11_suspicious_activity-main\\WhatsApp Video 2024-10-23 at 7.21.40 PM.mp4\")\n",
    "\n",
    "# Get the original frame dimensions and FPS\n",
    "frame_width = 600\n",
    "frame_height = 1020\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "# Define the codec and create a VideoWriter object with the original dimensions\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('output_original.mp4', fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "count = 0\n",
    "cy1, cy2, offset = 335, 380, 10\n",
    "inp, enter, exp, exitp = {}, [], {}, []\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    count += 1\n",
    "    if count % 3 != 0:\n",
    "        continue\n",
    "\n",
    "    # Run YOLO tracking on the frame, persisting tracks between frames\n",
    "    results = model.track(frame, persist=True, classes=0)\n",
    "\n",
    "    if results[0].boxes is not None and results[0].boxes.id is not None:\n",
    "        boxes = results[0].boxes.xyxy.int().cpu().tolist()\n",
    "        class_ids = results[0].boxes.cls.int().cpu().tolist()\n",
    "        track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "        confidences = results[0].boxes.conf.cpu().tolist()\n",
    "\n",
    "        for box, class_id, track_id, conf in zip(boxes, class_ids, track_ids, confidences):\n",
    "            c = names[class_id]\n",
    "            x1, y1, x2, y2 = box\n",
    "            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2\n",
    "\n",
    "            if cy1 - offset < cy < cy1 + offset:\n",
    "                inp[track_id] = (cx, cy)\n",
    "            if track_id in inp:\n",
    "                if cy2 - offset < cy < cy2 + offset:\n",
    "                    cv2.circle(frame, (cx, cy), 4, (255, 0, 0), -1)\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    cvzone.putTextRect(frame, f'{track_id}', (x1, y2), 1, 1)\n",
    "                    cvzone.putTextRect(frame, f'{c}', (x1, y1), 1, 1)\n",
    "                    if track_id not in enter:\n",
    "                        enter.append(track_id)\n",
    "\n",
    "            if cy2 - offset < cy < cy2 + offset:\n",
    "                exp[track_id] = (cx, cy)\n",
    "            if track_id in exp:\n",
    "                if cy1 - offset < cy < cy1 + offset:\n",
    "                    cv2.circle(frame, (cx, cy), 4, (255, 0, 0), -1)\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                    cvzone.putTextRect(frame, f'{track_id}', (x1, y2), 1, 1)\n",
    "                    cvzone.putTextRect(frame, f'{c}', (x1, y1), 1, 1)\n",
    "                    if track_id not in exitp:\n",
    "                        exitp.append(track_id)\n",
    "\n",
    "    # Draw entry and exit lines\n",
    "    cv2.line(frame, (6, cy1), (1018, cy1), (0, 0, 255), 2)\n",
    "    cv2.line(frame, (6, cy2), (1018, cy2), (255, 0, 255), 2)\n",
    "\n",
    "    # Display count of entered and exited persons\n",
    "    cvzone.putTextRect(frame, f'EnterPerson: {len(enter)}', (50, 60), 2, 2)\n",
    "    cvzone.putTextRect(frame, f'ExitPerson: {len(exitp)}', (50, 160), 2, 2)\n",
    "\n",
    "    # Write the frame to the output video\n",
    "    out.write(frame)\n",
    "\n",
    "    # Show the frame in a window\n",
    "    cv2.imshow(\"RGB\", frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
